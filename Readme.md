# Dual-Branch Zero-Shot Learning for Denoising in Fluorescence Lifetime Imaging Microscopy

## Data
### What Kind of Data I Need 
- I aim to mimic the approach from zero-shot methodologies, which means I only perform verification work.
- BPAE/3T3/Any other commonly used biological sample in FLIM/Confocal
- I & Q & A
### What Kind of Data I Have 
- MPG data 
- Natural Image Photo Data (CCD/CMOS)
- Some data Varum has used

The idea is to train A, but with the relationship between I & Q, we could possibly adopt a zero-shot learning-ish strategy.

All learning is based on the feature of A, so the feature I is the kernel. In FLIM, you must have an A to estimate g&s -> I&Q. 

Since we do not have complete pairs of (I,Q,A -> A (GT)), we do not even have such a thing, the best we can do is:
    
- Use MPG pretrained model for I/Q -> A optimization 
- Provide fine-tune purpose data (generated by myself) with (noised I / Q / A) -> (50 or even more averaged I/Q/A) 
- With other applications (which are not limited to FLIM) [May be a separate paper]
- **What if the input is g&s**?
- g & s & I & Q & A (stacks)

## Loss function Design
- Use their physical relationship
- MSE(A' - I'/Q') or some other design like image entropy
- Potential ZS Learning -> Try the way from ZS-N2N

### Validation of the Model and Performance
- Most validation is to present the data with some great figures.
- PSNR // SSIM could be used, anyway we have a pair of input & output.
- Compare with primitive results.

## Experiments

## TODO

- Few-shot Paper Reading
- Learn about how we could apply some vectors for this project
- And during the learning process, there should be no I and Q beenseen by the network (Make sure it is a zero-shot learning)
- If the I and Q are joined in the learning process, it should be not called ***Zero-Shot***, since it is a part of learning and been seen by system. But in our case
- Rethink about the network : like if input is I and Q and output is the clean A and how we make use of noisy A in this network?